{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "## You are using the Python ARM Radar Toolkit (Py-ART), an open source\n",
      "## library for working with weather radar data. Py-ART is partly\n",
      "## supported by the U.S. Department of Energy as part of the Atmospheric\n",
      "## Radiation Measurement (ARM) Climate Research Facility, an Office of\n",
      "## Science user facility.\n",
      "##\n",
      "## If you use this software to prepare a publication, please cite:\n",
      "##\n",
      "##     JJ Helmus and SM Collis, JORS 2016, doi: 10.5334/jors.119\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Import\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pyart\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rca_calculate_hdf5(filename):\n",
    "    '''Calculates the 95th percentile clutter area reflectivity and RCA using baseline and clutter map'''\n",
    "    from netCDF4 import Dataset\n",
    "    dataset = Dataset('/home/hunzinger/data/rca_baseline_20181109.nc')\n",
    "    PCT_on_50 = dataset.variables['Flagged clutter grid gates'][:,:]\n",
    "    vPCT_on_50 = dataset.variables['Flagged clutter grid gates (V)'][:,:]\n",
    "    dbz95_baseline = dataset.variables['Baseline 95th reflectivity'][:]\n",
    "    vdbz95_baseline = dataset.variables['Baseline 95th reflectivity (V)'][:]\n",
    "    dataset.close()\n",
    "    \n",
    "    radar = pyart.aux_io.read_gamic(filename, file_field_names=True) \n",
    "    #radar = pyart.io.cfradial.read_cfradial(filename)\n",
    "    date_time = radar.time['units'].replace('seconds since ', '')\n",
    "    \n",
    "    # Constrain range between 1 - 5 km\n",
    "    #r_start_idx = np.where(radar.range['data'] < 1000.)[0][-1]+1\n",
    "    r_start_idx = 0\n",
    "    r_stop_idx = np.where(radar.range['data'] > 10000.)[0][0]\n",
    "    \n",
    "    # Using lowest elevation angle of PPI (0.5 deg)\n",
    "    sweep_start_idx = radar.sweep_start_ray_index['data'][0]\n",
    "    sweep_stop_idx = radar.sweep_end_ray_index['data'][0]+1\n",
    "    \n",
    "    # Get variables (only the rays/gates needed)\n",
    "    #zh = radar.fields['reflectivity']['data'][sweep_start_idx:sweep_stop_idx,r_start_idx:r_stop_idx]\n",
    "    zh = radar.fields['Zh']['data'][sweep_start_idx:sweep_stop_idx,r_start_idx:r_stop_idx]\n",
    "    zv = radar.fields['Zv']['data'][sweep_start_idx:sweep_stop_idx,r_start_idx:r_stop_idx]\n",
    "    r = radar.range['data'][r_start_idx:r_stop_idx]\n",
    "    theta = radar.azimuth['data'][sweep_start_idx:sweep_stop_idx]\n",
    "    \n",
    "    # Eliminate duplicate azimuths to maintain a total # of azimuths of 360\n",
    "    if len(theta) > 360:\n",
    "        diff = len(theta) - 360\n",
    "        zh = np.delete(zh,-diff,axis=0)\n",
    "        zv = np.delete(zv,-diff,axis=0)\n",
    "        theta = np.delete(theta,-diff)\n",
    "        \n",
    "    # Arrange/sort azimuths to span 0 to 360 deg. from index 0 to 359\n",
    "    sorted_idx = np.argsort(theta)\n",
    "    zh = zh[sorted_idx,:]\n",
    "    zv = zv[sorted_idx]\n",
    "    theta = theta[sorted_idx]\n",
    "    \n",
    "    # Create array to store qualifying reflectivities (fall within PCT_on > 0.5)\n",
    "    zh_car = np.empty((zh.shape))\n",
    "    zh_car[:,:] = np.nan\n",
    "    zv_car = np.empty((zv.shape))\n",
    "    zv_car[:,:] = np.nan\n",
    "    \n",
    "    # Find and store all reflectivity values that fall within the PCT_on > 0.5 grid gate\n",
    "    for i in range(0,len(PCT_on_50[:,0])):\n",
    "        for j in range(0,len(PCT_on_50[0,:])):\n",
    "            if np.isfinite(PCT_on_50[i,j]):\n",
    "                zh_car[i,j*10-10:j*10] = zh[i,j*10-10:j*10]\n",
    "                \n",
    "    # Calculate the PDF of the clutter area reflectivity (CAR)\n",
    "    mask = np.where(np.isfinite(zh_car))  \n",
    "    #n,bins,patches=plt.hist(zh_car[mask],bins=105,range=(-40.,65.))\n",
    "    n,bins=np.histogram(zh_car[mask],bins=525,range=(-40.,65.))\n",
    "    \n",
    "    # Calculate CDF of clutter area reflectivity\n",
    "    cdf = np.cumsum(n)\n",
    "    p = cdf/cdf[-1]*100\n",
    "    \n",
    "    # Find coefficients of 13th degree polynomial for CDF\n",
    "    x = np.arange(525)*(1/5)-40\n",
    "    coeff = np.polyfit(p,x,13)\n",
    "    poly_func = np.poly1d(coeff)\n",
    "    #x_poly = np.linspace(p[0],p[-1],105)\n",
    "    #y_poly = poly_func(x_poly)\n",
    "    \n",
    "    # Find the value of reflectivity at the 95th percentile of CDF\n",
    "    dbz95 = poly_func(95.)\n",
    "    \n",
    "    # Calculate RCA\n",
    "    rca = dbz95_baseline - dbz95\n",
    "    \n",
    "    # V POLARIZATION\n",
    "    # Find and store all reflectivity values that fall within the PCT_on > 0.5 grid gate\n",
    "    for i in range(0,len(vPCT_on_50[:,0])):\n",
    "        for j in range(0,len(vPCT_on_50[0,:])):\n",
    "            if np.isfinite(vPCT_on_50[i,j]):\n",
    "                zv_car[i,j*10-10:j*10] = zv[i,j*10-10:j*10]\n",
    "                \n",
    "    # Calculate the PDF of the clutter area reflectivity (CAR)\n",
    "    mask = np.where(np.isfinite(zv_car))  \n",
    "    #vn,vbins,vpatches=plt.hist(zv_car[mask],bins=525,range=(-40.,65.))\n",
    "    vn,vbins=np.histogram(zv_car[mask],bins=525,range=(-40.,65.))\n",
    "    \n",
    "    # Calculate CDF of clutter area reflectivity\n",
    "    cdf = np.cumsum(vn)\n",
    "    vp = cdf/cdf[-1]*100\n",
    "    \n",
    "    # Find coefficients of 13th degree polynomial for CDF\n",
    "    x = np.arange(525)*(1/5)-40\n",
    "    coeff = np.polyfit(vp,x,13)\n",
    "    poly_func = np.poly1d(coeff)\n",
    "    #x_poly = np.linspace(p[0],p[-1],105)\n",
    "    #y_poly = poly_func(x_poly)\n",
    "    \n",
    "    # Find the value of reflectivity at the 95th percentile of CDF\n",
    "    dbz95_v = poly_func(95.)\n",
    "    \n",
    "    # Calculate RCA\n",
    "    vrca = vdbz95_baseline - dbz95_v\n",
    "    \n",
    "    del radar\n",
    "    return date_time, zh_car, n, bins, p, dbz95, dbz95_baseline, rca, zv_car, vn, vbins, vp, dbz95_v, vdbz95_baseline, vrca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/run/media/hunzinger/WININSTALL/csapr2-data/corcsaprM1.00.20181026.230003.raw.cor-ppi-cacti-15tilt_CSAPR2_20181026230003_00.h5\n",
      "/run/media/hunzinger/WININSTALL/csapr2-data/corcsaprM1.00.20181026.231503.raw.cor-ppi-cacti-15tilt_CSAPR2_20181026231503_00.h5\n",
      "/run/media/hunzinger/WININSTALL/csapr2-data/corcsaprM1.00.20181026.233003.raw.cor-ppi-cacti-15tilt_CSAPR2_20181026233003_00.h5\n",
      "/run/media/hunzinger/WININSTALL/csapr2-data/corcsaprM1.00.20181026.234503.raw.cor-ppi-cacti-15tilt_CSAPR2_20181026234503_00.h5\n"
     ]
    }
   ],
   "source": [
    "# Run this function on a bunch of files (try data from one day)\n",
    "import os\n",
    "import glob\n",
    "\n",
    "# Specify day of interest\n",
    "yr = '2018'\n",
    "mon = '10'\n",
    "day = '26'\n",
    "date = yr+mon+day\n",
    "\n",
    "# Specify path for that day\n",
    "filepath = '/home/hunzinger/data/ppi/'\n",
    "filepath = '/run/media/hunzinger/WININSTALL/csapr2-data'\n",
    "\n",
    "dt = []\n",
    "zh = []\n",
    "n = []\n",
    "bins = []\n",
    "cdf = []\n",
    "p = []\n",
    "dbz95 = []\n",
    "dbz95_baseline = []\n",
    "rca = []\n",
    "zv = []\n",
    "vn = []\n",
    "vbins = []\n",
    "vp = []\n",
    "vdbz95 = []\n",
    "vdbz95_baseline = []\n",
    "vrca = []\n",
    "\n",
    "for f in glob.glob(os.path.join(filepath, 'corcsaprM1*.'+date+'.23*cor-ppi*.h5')):\n",
    "    print(f)\n",
    "    DateTime, ZH, N, Bins, P, DBZ95, DBZ95BASE, RCA, ZV, VN, VBins, VP, VDBZ95, VDBZ95BASE, VRCA = rca_calculate_hdf5(f)\n",
    "    \n",
    "    # Put all PPI times into a list\n",
    "    dt.append(DateTime)\n",
    "    zh.append(ZH)\n",
    "    n.append(N)\n",
    "    bins.append(Bins)\n",
    "    p.append(P)\n",
    "    dbz95.append(DBZ95)\n",
    "    dbz95_baseline.append(DBZ95BASE)\n",
    "    rca.append(RCA)\n",
    "    zv.append(ZV)\n",
    "    vn.append(VN)\n",
    "    vbins.append(VBins)\n",
    "    vp.append(VP)\n",
    "    vdbz95.append(VDBZ95)\n",
    "    vdbz95_baseline.append(VDBZ95BASE)\n",
    "    vrca.append(VRCA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dbz95_min = np.nanmin(dbz95)\n",
    "#dbz95_max = np.nanmax(dbz95)\n",
    "#dbz95_std = np.nanstd(dbz95)\n",
    "dbz95_mean = np.nanmean(dbz95)\n",
    "\n",
    "#rca_min = np.nanmin(rca)\n",
    "#rca_max = np.nanmax(rca)\n",
    "#rca_std = np.nanstd(rca)\n",
    "#rca_mean = np.nanmean(rca)\n",
    "rca_mean = dbz95_baseline[0][0] - dbz95_mean\n",
    "\n",
    "#vdbz95_min = np.nanmin(vdbz95)\n",
    "#vdbz95_max = np.nanmax(vdbz95)\n",
    "#vdbz95_std = np.nanstd(vdbz95)\n",
    "vdbz95_mean = np.nanmean(vdbz95)\n",
    "\n",
    "#vrca_min = np.nanmin(vrca)\n",
    "#vrca_max = np.nanmax(vrca)\n",
    "#vrca_std = np.nanstd(vrca)\n",
    "#vrca_mean = np.nanmean(vrca)\n",
    "vrca_mean = vdbz95_baseline[0][0] - vdbz95_mean\n",
    "\n",
    "#date = dt[0][0:10]\n",
    "base = 0\n",
    "date = yr+'-'+mon+'-'+day\n",
    "import pandas as pd\n",
    "d = {'DATE':[date],'RCA_H':[rca_mean],'RCA_V':[vrca_mean],'BASELINE':[base]}\n",
    "dff = pd.DataFrame(data=d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import csv\n",
    "#with open('/home/hunzinger/data/rca_daily_values.csv', mode='w') as rca_file:\n",
    "#    fieldnames = ['Date', 'RCA', 'Baseline']\n",
    "#    writer = csv.DictWriter(rca_file, fieldnames=fieldnames)\n",
    "\n",
    "#    writer.writeheader()\n",
    "#    writer.writerow({'Date': date, 'RCA': rca_mean, 'Baseline': 1})\n",
    "    \n",
    "#with open('/home/hunzinger/data/rca_daily_values.csv', mode='a') as rca_file:\n",
    "#    writer = csv.writer(rca_file, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "\n",
    "#    writer.writerow([date, rca_mean, 1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         DATE     RCA_H     RCA_V  BASELINE\n",
      "0  2018-10-26  0.806336 -1.939349         0\n"
     ]
    }
   ],
   "source": [
    "print(dff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = '/home/hunzinger/data/rca_daily_values.csv'\n",
    "with open(filename, 'a') as f:\n",
    "    dff.to_csv(f, mode='a', header=f.tell()==0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0        DATE     RCA_H     RCA_V  BASELINE\n",
      "0           0  2018-11-09  0.000000  0.000000         1\n",
      "1           0  2018-11-08  1.367966  1.643013         0\n",
      "2           0  2018-10-26  0.806336 -1.939349         0\n"
     ]
    }
   ],
   "source": [
    "dat = pd.read_csv('/home/hunzinger/data/rca_daily_values.csv')\n",
    "print(dat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
